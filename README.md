Tutorial for loading the MAD-EEG dataset, a research corpus for studying EEG-based auditory attention decoding to a target instrument in polyphonic music that can be downloaded from [Zenodo](https://zenodo.org/records/4537751#.YS5MOI4zYuU)

The dataset consists of 20-channel EEG responses to music recorded from 8 subjects while attending to a particular instrument in a music mixture. 

For further details, please refer to the paper: [MAD-EEG: an EEG dataset for decoding auditory attention to a target instrument in polyphonic music](https://telecom-paris.hal.science/hal-02291882v1).

If you use the data in your research, please reference the paper (not just the Zenodo record):

@inproceedings{Cantisani2019,
  author={Giorgia Cantisani and Gabriel Trégoat and Slim Essid and Gaël Richard},
  title={{MAD-EEG: an EEG dataset for decoding auditory attention to a target instrument in polyphonic music}},
  year=2019,
  booktitle={Proc. SMM19, Workshop on Speech, Music and Mind 2019},
  pages={51--55},
  doi={10.21437/SMM.2019-11},
  url={http://dx.doi.org/10.21437/SMM.2019-11}
}
